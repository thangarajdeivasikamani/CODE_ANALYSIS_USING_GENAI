{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\det5cob\\.conda\\envs\\chromadbexp\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the go to File > Preferences > Settings > User tab > Extensions > python > Python Path  -- Setting.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone Github repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Backup_old_laptop\\\\Machine Learning\\\\Genrative_AI\\\\1iNeuron_Course\\\\20_30APR_24_\\\\CODE_ANALYSIS_USING_GENAI\\\\research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir test_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo 'C:\\\\Backup_old_laptop\\\\Machine Learning\\\\Genrative_AI\\\\1iNeuron_Course\\\\20_30APR_24_\\\\CODE_ANALYSIS_USING_GENAI\\\\research\\\\test_repo\\\\.git'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_path = \"test_repo/\"\n",
    "\n",
    "Repo.clone_from(\"https://github.com/thangarajdeivasikamani/MCQ_OPENAPI\", to_path=repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"test_repo/\"\n",
    "\n",
    "loader = GenericLoader.from_filesystem(repo_path+'/',\n",
    "                                        glob = \"**/*\",\n",
    "                                       suffixes=[\".py\"],\n",
    "                                       parser = LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='from setuptools import find_packages,setup\\n\\nsetup(\\n    name=\\'mcqgenrator\\',\\n    version=\\'0.0.1\\',\\n    author=\\'Thangaraj\\',\\n    author_email=\\'thangarajerode@gmail.com\\',\\n    install_requires=[\"openai\",\"langchain\",\"streamlit\",\"python-dotenv\",\"PyPDF2\"],\\n    packages=find_packages()\\n)', metadata={'source': 'test_repo\\\\setup.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import os\\nimport json\\nimport traceback\\nimport pandas as pd\\nfrom dotenv import load_dotenv\\nfrom mcqgenrator.utils import read_file,get_table_data\\nimport streamlit as st\\nfrom langchain.callbacks import get_openai_callback\\nfrom mcqgenrator.MCQGenrator import generate_evaluate_chain\\nfrom mcqgenrator.logger import logging\\n\\n#loading json file\\n\\nwith open(\\'Response.json\\', \\'r\\') as file:\\n    RESPONSE_JSON = json.load(file)\\n\\n#creating a title for the app\\nst.title(\"MCQs Creator Application with LangChain ü¶ú‚õìÔ∏è\")\\n\\n#Create a form using st.form\\nwith st.form(\"user_inputs\"):\\n    #File Upload\\n    uploaded_file=st.file_uploader(\"Uplaod a PDF or txt file\")\\n\\n    #Input Fields\\n    mcq_count=st.number_input(\"No. of MCQs\", min_value=3, max_value=50)\\n\\n    #Subject\\n    subject=st.text_input(\"Insert Subject\",max_chars=20)\\n\\n    # Quiz Tone\\n    tone=st.text_input(\"Complexity Level Of Questions\", max_chars=20, placeholder=\"Simple\")\\n\\n    #Add Button\\n    button=st.form_submit_button(\"Create MCQs\")\\n\\n    # Check if the button is clicked and all fields have input\\n\\n    if button and uploaded_file is not None and mcq_count and subject and tone:\\n        with st.spinner(\"loading...\"):\\n            try:\\n                text=read_file(uploaded_file)\\n                #Count tokens and the cost of API call\\n                with get_openai_callback() as cb:\\n                    response=generate_evaluate_chain(\\n                        {\\n                        \"text\": text,\\n                        \"number\": mcq_count,\\n                        \"subject\":subject,\\n                        \"tone\": tone,\\n                        \"response_json\": json.dumps(RESPONSE_JSON)\\n                            }\\n                    )\\n                #st.write(response)\\n\\n            except Exception as e:\\n                traceback.print_exception(type(e), e, e.__traceback__)\\n                st.error(\"Error\")\\n\\n            else:\\n                print(f\"Total Tokens:{cb.total_tokens}\")\\n                print(f\"Prompt Tokens:{cb.prompt_tokens}\")\\n                print(f\"Completion Tokens:{cb.completion_tokens}\")\\n                print(f\"Total Cost:{cb.total_cost}\")\\n                if isinstance(response, dict):\\n                    #Extract the quiz data from the response\\n                    quiz=response.get(\"quiz\", None)\\n                    if quiz is not None:\\n                        table_data=get_table_data(quiz)\\n                        if table_data is not None:\\n                            df=pd.DataFrame(table_data)\\n                            df.index=df.index+1\\n                            st.table(df)\\n                            #Display the review in atext box as well\\n                            st.text_area(label=\"Review\", value=response[\"review\"])\\n                        else:\\n                            st.error(\"Error in the table data\")\\n\\n                else:\\n                    st.write(response)\\n\\n\\n\\n', metadata={'source': 'test_repo\\\\StreamlitApp.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"import json\\nimport os\\nimport json\\nimport traceback\\nimport pandas as pd\\nfrom dotenv import load_dotenv\\nfrom mcqgenrator.utils import read_file,get_table_data\\nimport streamlit as st\\nfrom langchain.callbacks import get_openai_callback\\nfrom mcqgenrator.MCQGenrator import generate_evaluate_chain\\n\\n#loading json file\\nwith open('C:\\\\Complete_Content\\\\All_Project\\\\TEST_FOR_EVERYTHING\\\\langchain\\\\Response.json', 'r') as file:\\n    RESPONSE_JSON = json.load(file)\\n\\n#print(RESPONSE_JSON)\", metadata={'source': 'test_repo\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import logging\\nimport os\\nfrom datetime import datetime\\n\\nLOG_FILE=f\"{datetime.now().strftime(\\'%m_%d_%Y_%H_%M_%S\\')}.log\"\\n\\nlog_path=os.path.join(os.getcwd(),\"logs\")\\n\\nos.makedirs(log_path,exist_ok=True)\\n\\nLOG_FILEPATH=os.path.join(log_path,LOG_FILE)\\n\\n\\nlogging.basicConfig(level=logging.INFO, \\n                    filename=LOG_FILEPATH,\\n                    format=\"[%(asctime)s] %(lineno)d %(name)s - %(levelname)s - %(message)s\"\\n)', metadata={'source': 'test_repo\\\\mcqgenrator\\\\logger.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import os\\nimport json\\nimport traceback\\nimport pandas as pd\\nfrom dotenv import load_dotenv\\nfrom mcqgenrator.utils import read_file,get_table_data\\nfrom mcqgenrator.logger import logging\\n\\n#imporing necessary packages packages from langchain\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\nfrom langchain.chains import SequentialChain\\n\\n# Load environment variables from the .env file\\nload_dotenv()\\n\\n# Access the environment variables just like you would with os.environ\\nkey = os.getenv(\"OPENAI_API_KEY\")\\n\\nprint(\"Value of MY_VARIABLE:\", key)\\n\\nllm = ChatOpenAI(openai_api_key=key,model_name=\"gpt-3.5-turbo\", temperature=0.3)\\n\\ntemplate=\"\"\"\\nText:{text}\\nYou are an expert MCQ maker. Given the above text, it is your job to \\\\\\ncreate a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \\nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\\\\nEnsure to make {number} MCQs\\n### RESPONSE_JSON\\n{response_json}\\n\\n\"\"\"\\n\\nquiz_generation_prompt = PromptTemplate(\\n    input_variables=[\"text\", \"number\", \"grade\", \"tone\", \"response_json\"],\\n    template=template)\\n\\n\\n\\nquiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\\n\\ntemplate=\"\"\"\\nYou are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\\\\nYou need to evaluate the complexity of teh question and give a complete analysis of the quiz if the students\\nwill be able to unserstand the questions and answer them. Only use at max 50 words for complexity analysis. \\nif the quiz is not at par with the cognitive and analytical abilities of the students,\\\\\\nupdate tech quiz questions which needs to be changed  and change the tone such that it perfectly fits the student abilities\\nQuiz_MCQs:\\n{quiz}\\n\\nCheck from an expert English Writer of the above quiz:\\n\"\"\"\\n\\nquiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=template)\\n\\nreview_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\\n\\n\\n# This is an Overall Chain where we run the two chains in Sequence\\ngenerate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\\n                                        output_variables=[\"quiz\", \"review\"], verbose=True,)\\n', metadata={'source': 'test_repo\\\\mcqgenrator\\\\MCQGenrator.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import os\\nimport PyPDF2\\nimport json\\nimport traceback\\n\\ndef read_file(file):\\n    if file.name.endswith(\".pdf\"):\\n        try:\\n            pdf_reader=PyPDF2.PdfFileReader(file)\\n            text=\"\"\\n            for page in pdf_reader.pages:\\n                text+=page.extract_text()\\n            return text\\n            \\n        except Exception as e:\\n            raise Exception(\"error reading the PDF file\")\\n        \\n    elif file.name.endswith(\".txt\"):\\n        return file.read().decode(\"utf-8\")\\n    \\n    else:\\n        raise Exception(\\n            \"unsupported file format only pdf and text file suppoted\"\\n            )\\n\\ndef get_table_data(quiz_str):\\n    try:\\n        # convert the quiz from a str to dict\\n        quiz_dict=json.loads(quiz_str)\\n        quiz_table_data=[]\\n        \\n        # iterate over the quiz dictionary and extract the required information\\n        for key,value in quiz_dict.items():\\n            mcq=value[\"mcq\"]\\n            options=\" || \".join(\\n                [\\n                    f\"{option}-> {option_value}\" for option, option_value in value[\"options\"].items()\\n                 \\n                 ]\\n            )\\n            \\n            correct=value[\"correct\"]\\n            quiz_table_data.append({\"MCQ\": mcq,\"Choices\": options, \"Correct\": correct})\\n        \\n        return quiz_table_data\\n        \\n    except Exception as e:\\n        traceback.print_exception(type(e), e, e.__traceback__)\\n        return False\\n\\n\\n', metadata={'source': 'test_repo\\\\mcqgenrator\\\\utils.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='', metadata={'source': 'test_repo\\\\mcqgenrator\\\\__init__.py', 'language': <Language.PYTHON: 'python'>})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunkings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_splitter = RecursiveCharacterTextSplitter.from_language(language = Language.PYTHON,\n",
    "                                                             chunk_size = 2000,\n",
    "                                                             chunk_overlap = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = documents_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge base (vector DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory='./data')\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\det5cob\\.conda\\envs\\chromadbexp\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# llm = ChatOpenAI(model_name=\"gpt-4\")\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm, memory_key = \"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":3}), memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what i mean by st.spinner?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\det5cob\\.conda\\envs\\chromadbexp\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Number of requested results 20 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`st.spinner()` is a function in Streamlit, a popular Python library used for creating web applications with simple interactive elements. When you use `st.spinner()`, it displays a spinner animation on the web application interface, indicating to the user that some process is ongoing, such as loading data or calculations being performed. It is a visual cue to inform the user that the application is working on a task and they should wait for the process to complete.\n"
     ]
    }
   ],
   "source": [
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
